# Code for Meaningful Imitation Learning Benchmark (MILBench) project

This repo contains a benchmark for determining whether imitation learning
policies are "meaningful" in the sense of robustly acting in accordance with the
demonstrator's intent across many plausible environments. At the time of writing
(2019-11-11) it is a CS287 (robotics) project, but I hope I can steer it into
something publishable later on.
